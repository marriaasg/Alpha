{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOevobYrDLO36qaFuOouoQU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marriaasg/Alpha/blob/master/websiteLinkExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is simply downloading all the links in the website:"
      ],
      "metadata": {
        "id": "m1ejL2QKYfij"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JScCvtn8JR0e",
        "outputId": "7f27eb48-04f2-4bd4-88b1-a673df9ed11d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n",
            "mailto:alfio.ferrara@unimi.it\n",
            "#semantic-shift-detection-p1\n",
            "#entailment-in-language-pragmatics-p2\n",
            "#citation-detection-in-vatican-publications-p3\n",
            "#complexity-in-boardgames-p4\n",
            "#how-do-you-cultivate-your-field-p5\n",
            "#in-god-we-trust-p6\n",
            "#how-do-you-feel-my-dear-p7\n",
            "#find-hidden-entities-in-wikipedia-articles-p8\n",
            "#covid19-search-engine-p9\n",
            "#who-said-it--p10\n",
            "#the-winner-of-the-next-game-p11\n",
            "#making-history-count-p12\n",
            "#transcribing-the-letters-of-the-accademia-del-cimento-p13\n",
            "https: //www.springer.com/gp/computer-science/ lncs / conference-proceedings-guidelines\n",
            "https://github.com/\n",
            "https://refubium.fu-berlin.de/bitstream/handle/fub188/32534/303-TahmasebiEtAl-2021.pdf;jsessionid=52E6562F78EBD1CC3AB11EE0748F1A91?sequence=1\n",
            "https://aclanthology.org/2021.naacl-main.369/\n",
            "https://aclanthology.org/D19-1007/\n",
            "http://nlp.stanford.edu/pubs/snli_paper.pdf\n",
            "https://nlp.stanford.edu/projects/snli/\n",
            "https://hlt-nlp.fbk.eu/technologies/textual-entailment-graph-dataset\n",
            "https://arxiv.org/abs/2010.03061\n",
            "https://arxiv.org/abs/1709.04482\n",
            "http://www.vatican.va/content/vatican/it.html\n",
            "https://doi.org/10.1145/2600428.2609597\n",
            "https://doi.org/10.1145/2600428.2609597\n",
            "mailto:francesco.periti@unimi.it\n",
            "https://boardgamegeek.com\n",
            "https://boardgamegeek.com/boardgame/174430/gloomhaven\n",
            "https://www.gmtgames.com/\n",
            "https://boardgamegeek.com/wiki/page/BGG_XML_API2\n",
            "https://onlinelibrary.wiley.com/doi/pdf/10.5054/tq.2011.240859\n",
            "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0048386\n",
            "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7243219\n",
            "https://www.unimi.it/it/ugov/person/luca-bechini\n",
            "http://island.ricerca.di.unimi.it/~alfio/shared/agrotech.zip\n",
            "https://en.wikipedia.org/wiki/RIS_(file_format)\n",
            "https://unimibox.unimi.it/index.php/s/d4eEitbyczLdjwd\n",
            "http://www.foodvoc.org/page/Valerie-9\n",
            "http://aims.fao.org/vest-registry/vocabularies/agrovoc\n",
            "https://op.europa.eu/en/web/eu-vocabularies/th-concept/-/resource/eurovoc/100156?target=Browse\n",
            "https://air.unimi.it/handle/2434/481444#.Xq7I8ZpS_0Q\n",
            "https://www.aaai.org/ocs/index.php/FLAIRS/2010/paper/viewPaper/1380\n",
            "https://developer.twitter.com/en\n",
            "https://unimibox.unimi.it/index.php/s/2o5jqnZmzcDoaqk\n",
            "https://doi.org/10.1016/j.joi.2016.03.006\n",
            "https://doi.org/10.1145/3159652.3170461\n",
            "https://doi.org/10.1016/j.patter.2021.100263\n",
            "https://doi.org/10.1080/13537903.2012.642707\n",
            "https://doi.org/10.1080/0048721X.2014.904035\n",
            "https://doi.org/10.2307/3711934\n",
            "https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
            "https://github.com/JULIELab/EmoBank\n",
            "http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html\n",
            "https://www.kaggle.com/pashupatigupta/emotion-detection-from-text\n",
            "https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
            "https://ieeexplore.ieee.org/abstract/document/5610650\n",
            "http://aclweb.org/anthology/E17-2092\n",
            "http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html\n",
            "https://huggingface.co/datasets/wikipedia#dataset-card-for-wikipedia\n",
            "https://pdf.sciencedirectassets.com/271585/1-s2.0-S0004370212X00110/1-s2.0-S0004370212000446/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEEAaCXVzLWVhc3QtMSJHMEUCIGgYYj1QTiaaGjRpWYyAOWwoKcsS32stAbZYtJOtoqkHAiEAqbva0L4VkvEhPSAxWZuWfqwRNdpvNFBttHKAM5CwVPAq0gQIGRAEGgwwNTkwMDM1NDY4NjUiDGE5wqktLGDJdXdTFyqvBPydiAITZb/1qxcrGWiQnyd1HZL6jELvrjD2sO4Ht+e1Z/xDerIRdhExX3Ei43sRMZXJdVM3L0L8pRhjVK8FTeDiQHXiptnGnr2jccC4e1bNUaE+sNbQlIYQ+cNzF3Kt7BtmTnQ+MM0AxZD7FvH8BWi8F0soP0aAmlmVRpT5+NMeUQxNLCFzy0VddOb9EoyUIBqc1htRGUaE8SOHzXNOwS35gSdQOJi0ZjURnxIJrvbX89Y+kMK74KoSaxvwrf4calDvWRzLvL6QBipMBJ5a72tx5j43pqTBUWwbR93tyhpMbi8csPv6yYW5ewrQjhcLgzkLj4AVvA77RgBhM0DDsvdHpbILduiAjKBnd8roJwj4h9t/ruRVKHpqw2lQkGljKj8l5NF2oBiP/u/uYisSLfTpdFSkbRQjm5scUvpC3DhawNwUsQuwzVnlBOtPluo70r12dnfneD23gnhZFBYcvDjQph6mRXMC7cWV0xTRNGoUodnNtV7wvdfPqLhtub4qCvScnmesci1mJIlh+JL4oU/HC77jnVCdaIdnsAcCPpknRKbfbBXxOhWZoey2atEtPFX/Ffgj6BunDuz/BFyLZtLKLmeolh7QCdz+IM5dp9QNflQDstWvnEWo4M437KjjQlibkWlNk4jvifJ7nTsU8jaHp4lZvWHKfvto38X45pmAuOtdZcRMjoC3VbfriArTs8DSiPcesNltCEaqrLJVGIgfWC4ji26vukeKKxacmuEwm4jqkwY6qQFiADtQ+YS0lObGzS0ODD4fwv/2YvtQO4l+/U7DyWz3QvWnIlPIkJ3rVt+vquptNBWCc/eX4orZGbXZ7V2Qggr6FoEarkt002TD2cLX40NLyrTdswXdOrQI7jTnJwi1WpBhz5Z9y1YfUGKc46+sMP7K88n4xn6X+LruEJKEi3NYFBwX8Obe18NZWhOlrHRTBt6j75hCM17YccG+zSOqh8VAO8ugYaF/n97j&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220510T161023Z&X-Amz-SignedHeaders=host&X-Amz-Expires=299&X-Amz-Credential=ASIAQ3PHCVTYVG47SGXE/20220510/us-east-1/s3/aws4_request&X-Amz-Signature=9e20774b630ec844e21334b7c70d3dcbb4c4794a0852bf6fb661def78e7da548&hash=8664f6de8ce2884bdbc22a7c0aeb0b5bb9e31f39d2d406a5fbbe6c1dd0cee9ee&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0004370212000446&tid=spdf-3d504b5d-0e1d-4244-adec-6b692c60fd16&sid=9d16e70070ef1749c48bdc96e8985987095fgxrqb&type=client&ua=52575d52055706555101&rr=7093f1d57cf0a321\n",
            "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7243219\n",
            "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6823700\n",
            "https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset\n",
            "https://nihcc.app.box.com/v/DeepLesion\n",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3824925/pdf/10278_2013_Article_9619.pdf\n",
            "https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-5/issue-03/036501/DeepLesion--automated-mining-of-large-scale-lesion-annotations-and/10.1117/1.JMI.5.3.036501.full?SSO=1\n",
            "https://dati.camera.it/it/linked-data/\n",
            "https://dati.camera.it/it/linked-data/\n",
            "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7243219\n",
            "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6823700\n",
            "https://dl.acm.org/doi/pdf/10.1145/2433396.2433431\n",
            "https://www.sciencedirect.com/science/article/pii/S0169023X17305839\n",
            "https://arxiv.org/abs/1506.07220\n",
            "#dfref-footnote-1\n",
            "https://github.com/dhfbk/Histo\n",
            "https://www.english-corpora.org/coha\n",
            "https://www.mediawiki.org/wiki/API:Main_page\n",
            "https://pypi.org/project/wikipedia\n",
            "https://onlinelibrary.wiley.com/doi/full/10.1111/coin.12017\n",
            "https://escholarship.org/uc/item/4111f1fw\n",
            "https://dl.acm.org/doi/10.5555/2107636.2107642\n",
            "https://bibdig.museogalileo.it/Teca/Viewer;jsessionid=880AE04C39129A19F13B3B7A2363BC3C?an=27246&vis=D#page/4/mode/2up\n",
            "https://hal.archives-ouvertes.fr/hal-01913435/document\n",
            "https://link.springer.com/chapter/10.1007/978-3-030-89131-2_31\n",
            "https://www.mitpressjournals.org/doi/full/10.1162/coli_a_00347\n",
            "#ref-footnote-1\n"
          ]
        }
      ],
      "source": [
        "#how to download all the files from a website\n",
        "\n",
        "!pip install beautifulsoup4\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = 'https://contents.islab.di.unimi.it/teaching/courseprojects/inforet-projects-2021-22.html#how-do-you-feel-my-dear-p7' # Replace with the URL of the website you want to scrape\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "links = soup.find_all('a')\n",
        "for link in links:\n",
        "    href = link.get('href')\n",
        "    print(href)\n",
        "\n",
        "#download all the files from a website"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is downloading all the links between two specifit text:"
      ],
      "metadata": {
        "id": "JOUEOq_rYoCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = 'https://contents.islab.di.unimi.it/teaching/courseprojects/inforet-projects-2021-22.html#how-do-you-feel-my-dear-p7' # Replace with the URL of the website you want to scrape\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Specify the start and end sentences between which you want to extract the links\n",
        "start_sentence = \"How do you feel, my dear (P7)\"\n",
        "end_sentence = \"Find Hidden Entities in Wikipedia Articles (P8)\"\n",
        "\n",
        "# Find the start and end elements based on the sentences\n",
        "start_element = soup.find(string=start_sentence)\n",
        "end_element = soup.find(string=end_sentence)\n",
        "\n",
        "# Find all the links between the start and end elements\n",
        "links = []\n",
        "current_element = start_element.next_element\n",
        "while current_element != end_element:\n",
        "    if current_element.name == 'a':\n",
        "        href = current_element.get('href')\n",
        "        links.append(href)\n",
        "    current_element = current_element.next_element\n",
        "\n",
        "# Print the extracted links\n",
        "for link in links:\n",
        "    print(link)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh8VhfwwJtn2",
        "outputId": "fe7c28ce-1347-4ac2-c47b-830377a4093d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
            "https://github.com/JULIELab/EmoBank\n",
            "http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html\n",
            "https://www.kaggle.com/pashupatigupta/emotion-detection-from-text\n",
            "https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
            "https://ieeexplore.ieee.org/abstract/document/5610650\n",
            "http://aclweb.org/anthology/E17-2092\n",
            "http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an updated version of the upper code which is extracting the link texts as well:"
      ],
      "metadata": {
        "id": "-dg9I8OtYyoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = 'https://contents.islab.di.unimi.it/teaching/courseprojects/inforet-projects-2021-22.html#how-do-you-feel-my-dear-p7' # Replace with the URL of the website you want to scrape\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Specify the start and end sentences between which you want to extract the links\n",
        "start_sentence = \"How do you feel, my dear (P7)\"\n",
        "end_sentence = \"Find Hidden Entities in Wikipedia Articles (P8)\"\n",
        "\n",
        "# Find the start and end elements based on the sentences\n",
        "start_element = soup.find(string=start_sentence)\n",
        "end_element = soup.find(string=end_sentence)\n",
        "\n",
        "# Find all the links between the start and end elements\n",
        "links = []\n",
        "current_element = start_element.next_element\n",
        "while current_element != end_element:\n",
        "    if current_element.name == 'a':\n",
        "        href = current_element.get('href')\n",
        "        link_text = current_element.get_text()\n",
        "        links.append((href, link_text))\n",
        "    current_element = current_element.next_element\n",
        "\n",
        "# Print the extracted links and their link text\n",
        "for link in links:\n",
        "    href, link_text = link\n",
        "    print(f\"Link Text: {link_text}\")\n",
        "    print(f\"Link URL: {href}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpjoKAQeKWfY",
        "outputId": "e97cc55a-c850-4c57-b63e-6aa1ac903073"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Link Text: Cornell Movie--Dialogs Corpus\n",
            "Link URL: https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
            "\n",
            "Link Text: EmoBank\n",
            "Link URL: https://github.com/JULIELab/EmoBank\n",
            "\n",
            "Link Text: WASSA-2017\n",
            "Link URL: http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html\n",
            "\n",
            "Link Text: Emotion Detection from Text\n",
            "Link URL: https://www.kaggle.com/pashupatigupta/emotion-detection-from-text\n",
            "\n",
            "Link Text: Cornell Movie-Dialogs Corpus\n",
            "Link URL: https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
            "\n",
            "Link Text: link\n",
            "Link URL: https://ieeexplore.ieee.org/abstract/document/5610650\n",
            "\n",
            "Link Text: http://aclweb.org/anthology/E17-2092\n",
            "Link URL: http://aclweb.org/anthology/E17-2092\n",
            "\n",
            "Link Text: webpage\n",
            "Link URL: http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html\n",
            "\n"
          ]
        }
      ]
    }
  ]
}